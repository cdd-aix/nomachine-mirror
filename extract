#!/usr/bin/env python3
# coding: utf-8


import argparse
import re

from bs4 import BeautifulSoup


class Rule(object):
    """BeautifulSoup Rules

    """
    def __init__(self, regex, name, attrs):
        self.re = re.compile(regex)
        self.name = name
        self.attrs = attrs

    def find_all_get_group(self, soup):
        founditems = set()
        for item in soup.find_all(name=self.name,
                                  attrs={self.attrs: self.re}):
            founditems.add(self.re.search(item.get(self.attrs)).group(1))
        return founditems


def main(argv):
    flavors = dict(
        product=(Rule(regex='^(/download/.*&id=.*)$', name='a', attrs='href'),
                 Rule(regex="location\\.href='(/download/[^']+)'", name='div',
                      attrs='onclick')),
        download=(Rule(regex="^saveck\\('[^']+','([^']+)'\\)", name='a',
                       attrs='onclick'),)
    )
    parser = argparse.ArgumentParser(
        description='Extract NoMachine Product Download URLs')
    parser.add_argument('flavor', type=str,
                        help='parser flavor "product" or "download"')
    parser.add_argument('files', type=str, nargs='+',
                        help='HTML files to search for Product Download URLS')
    args = parser.parse_args()
    rules = flavors.get(args.flavor)
    extract(rules, args.files)


def extract(rules, files):
    found = set()
    for f in files:
        with open(f) as fp:
            soup = BeautifulSoup(fp, 'html.parser')
            for rule in rules:

                found.update(rule.find_all_get_group(soup))

    for item in sorted(found):
        print(item)


if __name__ == '__main__':
    import sys
    sys.exit(main(sys.argv))
